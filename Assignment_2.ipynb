{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT5135 Research Topics in AI\n",
    "\n",
    "## Assignment 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student ID(s): 22229358, 22230186, 20230220\n",
    "* Student name(s): KOSTADIN GEORGIEV, YAMINI GIRKAR, SHUBHAM MANGLAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, activations, models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_directory(dir, callback, label=None):\n",
    "    for dirname, _, filenames in os.walk(dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                id = filename[:-4]\n",
    "                pathname = os.path.join(dirname, filename)\n",
    "                im = Image.open(pathname)\n",
    "                imnp = np.array(im, dtype=float)\n",
    "\n",
    "                if len(imnp.shape) != 3:\n",
    "                    print(\"This is 1 channel, so we omit it\",\n",
    "                          imnp.shape, filename)\n",
    "                    continue\n",
    "\n",
    "                callback(id, imnp, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 1 channel, so we omit it (683, 1024) 4b9ef3ce2685ee32.jpg\n",
      "This is 1 channel, so we omit it (914, 1024) 5a71db307230880e.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>channels</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01ad3ff1d94eb557</th>\n",
       "      <td>670</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0346463867a297f4</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038fae9e70c4c3f1</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>053608552d63f724</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>053dab62fbb47736</th>\n",
       "      <td>682</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb4d2e0c0252fdc2</th>\n",
       "      <td>682</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb4f5968c7866a3e</th>\n",
       "      <td>699</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4495f8511553631</th>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8d3c3d8be68c4fd</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8e3dd41b584f645</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  height  width  channels       label\n",
       "01ad3ff1d94eb557     670   1024         3      alpaca\n",
       "0346463867a297f4     768   1024         3      alpaca\n",
       "038fae9e70c4c3f1     768   1024         3      alpaca\n",
       "053608552d63f724     768   1024         3      alpaca\n",
       "053dab62fbb47736     682   1024         3      alpaca\n",
       "...                  ...    ...       ...         ...\n",
       "eb4d2e0c0252fdc2     682   1024         3  not_alpaca\n",
       "eb4f5968c7866a3e     699   1024         3  not_alpaca\n",
       "f4495f8511553631     680   1024         3  not_alpaca\n",
       "f8d3c3d8be68c4fd     768   1024         3  not_alpaca\n",
       "f8e3dd41b584f645     768   1024         3  not_alpaca\n",
       "\n",
       "[325 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['height', 'width', 'channels', 'label'])\n",
    "\n",
    "def get_img_shape(id, imnp, label):\n",
    "    height, width, channel = imnp.shape\n",
    "    df.loc[id] = [height, width, channel, label]\n",
    "\n",
    "walk_directory('dataset/alpaca', get_img_shape, 'alpaca')\n",
    "walk_directory('dataset/not_alpaca', get_img_shape, 'not_alpaca')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be resized to 481 x 583\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = df['height'].min()\n",
    "IMG_WIDTH = df['width'].min()\n",
    "\n",
    "print('Images will be resized to', IMG_HEIGHT, 'x', IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(label):\n",
    "    source_dir = 'dataset/' + label\n",
    "    target_dir = 'dataset_resized/'+ label\n",
    "    subset = df.loc[df['label'] == label]\n",
    "\n",
    "    for id, image in subset.iterrows():\n",
    "        id = str(id)\n",
    "        filename = id + \".jpg\"\n",
    "        \n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        image = Image.open(source_path)\n",
    "        image = image.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "        image.save(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_images('alpaca')\n",
    "resize_images('not_alpaca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dir):\n",
    "    img_array = []\n",
    "    \n",
    "    walk_directory(dir, lambda id, imnp, label: img_array.append(imnp))\n",
    "\n",
    "    return np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpaca = load_images('dataset_resized/alpaca')\n",
    "img_not_alpaca = load_images('dataset_resized/not_alpaca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca: (142, 481, 583, 3)\n",
      "not_alpaca: (183, 481, 583, 3)\n"
     ]
    }
   ],
   "source": [
    "print('alpaca:', img_alpaca.shape)\n",
    "print('not_alpaca:', img_not_alpaca.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Proposed Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagram of the proposed convolution operation:\n",
    "\n",
    "![Proposed Layer](img/proposed_layer.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo code for signle training iteration of the proposed layer:\n",
    "\n",
    "\n",
    "```\n",
    "forward_pass(X):\n",
    "    n_samples, height, width, channels = X.shape\n",
    "    z = []\n",
    "\n",
    "    for x in X:\n",
    "        z_ = []\n",
    "        for w, b in zip(self.W, self.B):\n",
    "            for i in range(height - 2):\n",
    "                for j in range(width - 2):\n",
    "                    xrf = x[i:i+3, j:j+3, :]\n",
    "                    wrf = w[i:i+3, j:j+3, :]\n",
    "                    z_[i, j] = sum(xrf * wrf + b)\n",
    "        z.append(z_)\n",
    "    \n",
    "    a = activation(z)\n",
    "\n",
    "    return a\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposedLayer(layers.Layer):\n",
    "    def __init__(self, filters, receptive_field_size=(3, 3), activation=None, **kwargs):\n",
    "        super(ProposedLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.receptive_field_size = receptive_field_size\n",
    "        self.activation = activations.get(activation)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        n_samples, height, width, channels = input_shape\n",
    "\n",
    "        self.W = self.add_weight(name='kernel',\n",
    "                                 shape=(height, width, channels, self.filters),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.B = self.add_weight(name='bias',\n",
    "                                 shape=(self.filters,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        super(ProposedLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        n_samples, height, width, channels = X.shape\n",
    "        z = []\n",
    "\n",
    "        for x in X:\n",
    "            z_ = np.zeros((height-2, width-2, self.filters))\n",
    "\n",
    "            for i in range(self.filters):\n",
    "                w = self.W[:, :, :, i]\n",
    "                b = self.B[i]\n",
    "                z__ = z_[:, :, i]\n",
    "\n",
    "                for i in range(height - 2):\n",
    "                    for j in range(width - 2):\n",
    "                        xrf = x[i:i+3, j:j+3, :]\n",
    "                        wrf = w[i:i+3, j:j+3, :]\n",
    "                        z__[i, j] = tf.math.reduce_sum(tf.matmul(xrf, wrf) + b)\n",
    "                \n",
    "                z_[:, :, i] = z__\n",
    "\n",
    "            #def conv(w, b):\n",
    "            #    for i in range(height - 2):\n",
    "            #        for j in range(width - 2):\n",
    "            #            xrf = x[i:i+3, j:j+3, :]\n",
    "            #            wrf = w[i:i+3, j:j+3, :]\n",
    "            #            z_[i, j] = tf.math.reduce_sum(tf.matmul(xrf, wrf) + b)\n",
    "            #\n",
    "            #weights = tf.stack([self.W.T, self.B], axis=1)\n",
    "            #tf.map_fn(conv, weights)\n",
    "            z.append(z_)\n",
    "        \n",
    "        return self.activation(z)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        rf = self.receptive_field_size\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[1] = (input_shape[1] - rf[0]) // 1 + 1\n",
    "        output_shape[2] = (input_shape[2] - rf[1]) // 1 + 1\n",
    "        output_shape[3] = self.filters\n",
    "\n",
    "        return tuple(output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 481, 583, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 479, 581, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 239, 290, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 237, 288, 12)      1740      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 118, 144, 12)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 116, 142, 8)       872       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 58, 71, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 540)               17790300  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1082      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,794,442\n",
      "Trainable params: 17,794,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (225, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "n_classes = 2\n",
    "\n",
    "# Input\n",
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "# Block 1\n",
    "x0 = layers.Conv2D(16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x0)\n",
    "# Block 2\n",
    "x2 = layers.Conv2D(12, kernel_size=(3, 3), activation='relu')(x1)\n",
    "x3 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "# Block 3\n",
    "x4 = layers.Conv2D(8, kernel_size=(3, 3), activation='relu')(x3)\n",
    "x5 = layers.MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "\n",
    "# Flatten feature map - embedding size will become 34560\n",
    "x6 = layers.Flatten()(x5)\n",
    "\n",
    "# Dense layer for classification\n",
    "# Start with units in dense layer = embedding_size / 64\n",
    "x7 = layers.Dense(540, activation='relu')(x6)\n",
    "# Output\n",
    "outputs = layers.Dense(n_classes, activation='softmax')(x7)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"proposed_layer_95\" (type ProposedLayer).\n\nin user code:\n\n    File \"C:\\Users\\kosta\\AppData\\Local\\Temp\\ipykernel_12684\\2618982689.py\", line 38, in call  *\n        z__[i, j] = tf.math.reduce_sum(tf.matmul(xrf, wrf) + b)\n\n    ValueError: setting an array element with a sequence.\n\n\nCall arguments received by layer \"proposed_layer_95\" (type ProposedLayer):\n  â€¢ X=tf.Tensor(shape=(None, 481, 583, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[259], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m inputs \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(input_shape)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Block 1\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m x0 \u001b[39m=\u001b[39m ProposedLayer(\u001b[39m16\u001b[39;49m, receptive_field_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m)(inputs)\n\u001b[0;32m      9\u001b[0m x1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))(x0)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Block 2\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenh3qgroc.py:71\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     69\u001b[0m xrf \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mxrf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m j \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mj\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m ag__\u001b[39m.\u001b[39mfor_stmt(ag__\u001b[39m.\u001b[39mld(X), \u001b[39mNone\u001b[39;00m, loop_body_3, get_state_3, set_state_3, (), {\u001b[39m'\u001b[39m\u001b[39miterate_names\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     72\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenh3qgroc.py:60\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body_3\u001b[1;34m(itr_3)\u001b[0m\n\u001b[0;32m     58\u001b[0m     ag__\u001b[39m.\u001b[39mfor_stmt(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mrange\u001b[39m), (ag__\u001b[39m.\u001b[39mld(height) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39mNone\u001b[39;00m, loop_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m,), {\u001b[39m'\u001b[39m\u001b[39miterate_names\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     59\u001b[0m     ag__\u001b[39m.\u001b[39mld(z_)[:, :, ag__\u001b[39m.\u001b[39mld(i)] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(z__)\n\u001b[1;32m---> 60\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mrange\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfilters,), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body_2, get_state_2, set_state_2, (), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[0;32m     61\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(z)\u001b[39m.\u001b[39mappend, (ag__\u001b[39m.\u001b[39mld(z_),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenh3qgroc.py:58\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body_3.<locals>.loop_body_2\u001b[1;34m(itr_2)\u001b[0m\n\u001b[0;32m     56\u001b[0m         ag__\u001b[39m.\u001b[39mld(z__)[ag__\u001b[39m.\u001b[39mld(i), ag__\u001b[39m.\u001b[39mld(j)] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmatmul, (ag__\u001b[39m.\u001b[39mld(xrf), ag__\u001b[39m.\u001b[39mld(wrf)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(b),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     57\u001b[0m     ag__\u001b[39m.\u001b[39mfor_stmt(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mrange\u001b[39m), (ag__\u001b[39m.\u001b[39mld(width) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39mNone\u001b[39;00m, loop_body, get_state, set_state, (), {\u001b[39m'\u001b[39m\u001b[39miterate_names\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mj\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m---> 58\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mrange\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(height) \u001b[39m-\u001b[39;49m \u001b[39m2\u001b[39;49m,), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body_1, get_state_1, set_state_1, (\u001b[39m'\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m'\u001b[39;49m,), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[0;32m     59\u001b[0m ag__\u001b[39m.\u001b[39mld(z_)[:, :, ag__\u001b[39m.\u001b[39mld(i)] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(z__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenh3qgroc.py:57\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body_3.<locals>.loop_body_2.<locals>.loop_body_1\u001b[1;34m(itr_1)\u001b[0m\n\u001b[0;32m     55\u001b[0m     wrf \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(w)[ag__\u001b[39m.\u001b[39mld(i):ag__\u001b[39m.\u001b[39mld(i) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, ag__\u001b[39m.\u001b[39mld(j):ag__\u001b[39m.\u001b[39mld(j) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, :]\n\u001b[0;32m     56\u001b[0m     ag__\u001b[39m.\u001b[39mld(z__)[ag__\u001b[39m.\u001b[39mld(i), ag__\u001b[39m.\u001b[39mld(j)] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmatmul, (ag__\u001b[39m.\u001b[39mld(xrf), ag__\u001b[39m.\u001b[39mld(wrf)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(b),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 57\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mrange\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(width) \u001b[39m-\u001b[39;49m \u001b[39m2\u001b[39;49m,), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body, get_state, set_state, (), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mj\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenh3qgroc.py:56\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body_3.<locals>.loop_body_2.<locals>.loop_body_1.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     54\u001b[0m xrf \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(x)[ag__\u001b[39m.\u001b[39mld(i):ag__\u001b[39m.\u001b[39mld(i) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, ag__\u001b[39m.\u001b[39mld(j):ag__\u001b[39m.\u001b[39mld(j) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, :]\n\u001b[0;32m     55\u001b[0m wrf \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(w)[ag__\u001b[39m.\u001b[39mld(i):ag__\u001b[39m.\u001b[39mld(i) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, ag__\u001b[39m.\u001b[39mld(j):ag__\u001b[39m.\u001b[39mld(j) \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, :]\n\u001b[1;32m---> 56\u001b[0m ag__\u001b[39m.\u001b[39;49mld(z__)[ag__\u001b[39m.\u001b[39;49mld(i), ag__\u001b[39m.\u001b[39;49mld(j)] \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmatmul, (ag__\u001b[39m.\u001b[39mld(xrf), ag__\u001b[39m.\u001b[39mld(wrf)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(b),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"proposed_layer_95\" (type ProposedLayer).\n\nin user code:\n\n    File \"C:\\Users\\kosta\\AppData\\Local\\Temp\\ipykernel_12684\\2618982689.py\", line 38, in call  *\n        z__[i, j] = tf.math.reduce_sum(tf.matmul(xrf, wrf) + b)\n\n    ValueError: setting an array element with a sequence.\n\n\nCall arguments received by layer \"proposed_layer_95\" (type ProposedLayer):\n  â€¢ X=tf.Tensor(shape=(None, 481, 583, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "n_classes = 2\n",
    "\n",
    "# Input\n",
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "# Block 1\n",
    "x0 = ProposedLayer(16, receptive_field_size=(3, 3), activation='relu')(inputs)\n",
    "x1 = layers.MaxPooling2D(pool_size=(2, 2))(x0)\n",
    "# Block 2\n",
    "x2 = ProposedLayer(12, receptive_field_size=(3, 3), activation='relu')(x1)\n",
    "x3 = layers.MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "# Block 3\n",
    "x4 = ProposedLayer(8, receptive_field_size=(3, 3), activation='relu')(x3)\n",
    "x5 = layers.MaxPooling2D(pool_size=(2, 2))(x4)\n",
    "\n",
    "# Flatten feature map - embedding size will become 34560\n",
    "x6 = layers.Flatten()(x5)\n",
    "\n",
    "# Dense layer for classification\n",
    "# Start with units in dense layer = embedding_size / 64\n",
    "x7 = layers.Dense(540, activation='relu')(x6)\n",
    "# Output\n",
    "outputs = layers.Dense(n_classes, activation='softmax')(x7)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
